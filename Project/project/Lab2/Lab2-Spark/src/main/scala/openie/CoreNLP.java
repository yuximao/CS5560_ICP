package openie;

import edu.stanford.nlp.coref.CorefCoreAnnotations;
import edu.stanford.nlp.coref.data.CorefChain;
import edu.stanford.nlp.ie.util.RelationTriple;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.naturalli.NaturalLogicAnnotations;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;
import edu.stanford.nlp.semgraph.SemanticGraph;
import edu.stanford.nlp.semgraph.SemanticGraphCoreAnnotations;
import edu.stanford.nlp.simple.Document;
import edu.stanford.nlp.simple.Sentence;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TreeCoreAnnotations;
import edu.stanford.nlp.util.CoreMap;
import edu.stanford.nlp.util.Quadruple;
import scala.collection.mutable.ArrayBuffer;

import java.io.*;
import java.util.*;


/**
 * Created by Mayanka on 13-Jun-16.
 */
public class CoreNLP {
    public static List<CoreMap> returnSentences(String text) {

        // creates a StanfordCoreNLP object, with POS tagging, lemmatization, NER, parsing, and coreference resolution
        Properties props = new Properties();
        props.setProperty("annotators", "tokenize,ssplit,pos,lemma,ner,parse,dcoref,depparse,natlog,openie");
        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);

        // create an empty Annotation just with the given text
        Annotation document = new Annotation(text);

        // run all Annotators on this text
        pipeline.annotate(document);

        // these are all the sentences in this document
        // a CoreMap is essentially a Map that uses class objects as keys and has values with custom types
        List<CoreMap> sentences = document.get(CoreAnnotations.SentencesAnnotation.class);

        System.out.println("Created Sentences");

        return sentences;
    }

    public static String returnPOS(List<CoreMap> text) {

        StringBuilder sb = new StringBuilder();

        for (CoreMap sentence : text) {
            // traversing the words in the current sentence
            // a CoreLabel is a CoreMap with additional token-specific methods
            for (CoreLabel token : sentence.get(CoreAnnotations.TokensAnnotation.class)) {

                System.out.println(token);

                // this is the text of the token
                String word = token.get(CoreAnnotations.TextAnnotation.class);
                System.out.println("Text Annotation");
                System.out.println(token + ":" + word);

                // this is the POS tag of the token
                String pos = token.get(CoreAnnotations.PartOfSpeechAnnotation.class);
                System.out.println("POS");
                System.out.println(token + ":" + pos);

                sb.append(word).append("\t").append(pos).append("\n");

            }
        }
        return sb.toString();
    }

    public static String returnTriplets(List<CoreMap> sentences) {

        StringBuilder sb = new StringBuilder();

        // Loop over sentences in the document
        for (CoreMap sentence : sentences) {
            // Get the OpenIE triples for the sentence
            Collection<RelationTriple> triples =
                    sentence.get(NaturalLogicAnnotations.RelationTriplesAnnotation.class);
            // Print the triples
            for (RelationTriple triple : triples) {
                System.out.println(triple.confidence + "\t" +
                        triple.subjectLemmaGloss() + "\t" +
                        triple.relationLemmaGloss() + "\t" +
                        triple.objectLemmaGloss());

                sb.append(triple.confidence).append("\t")
                        .append(triple.subjectLemmaGloss()).append("\t")
                        .append(triple.relationLemmaGloss()).append("\t")
                        .append(triple.objectLemmaGloss()).append("\n");
            }
        }

        return sb.toString();

    }

    public static String returnLongestTriplet(String text) {

        StringBuilder sb = new StringBuilder();

        Properties props = new Properties();
        props.setProperty("annotators", "tokenize,ssplit,pos,lemma,depparse,natlog,openie");
        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);

        Annotation doc = new Annotation(text);
        pipeline.annotate(doc);

        // Loop over sentences in the document
        for (CoreMap sentence : doc.get(CoreAnnotations.SentencesAnnotation.class)) {
            String longestTriple = "";

            // Get the OpenIE triples for the sentence
            Collection<RelationTriple> triples =
                    sentence.get(NaturalLogicAnnotations.RelationTriplesAnnotation.class);
            // Print the triples
            for (RelationTriple triple : triples) {
                System.out.println(triple.subjectLemmaGloss() + "\t" +
                        triple.relationLemmaGloss() + "\t" +
                        triple.objectLemmaGloss());

                String runTriple = triple.subjectLemmaGloss() + "\t" +
                        triple.relationLemmaGloss() + "\t" +
                        triple.objectLemmaGloss();

                if (longestTriple.length() < runTriple.length())
                    longestTriple = runTriple;
            }

            // Append largest triplet to final string.
            sb.append(longestTriple).append("\n");
        }

        return sb.toString();

    }

    private static String findLongestString(ArrayList<String> text) {
        String longestString = " ";
        if (!text.isEmpty()) {
            longestString = text.get(0);
            for (int i = 1; i < text.size(); i++)
                if (text.get(i).length() > longestString.length())
                    longestString = text.get(i);
        }

        return longestString;
    }

}
